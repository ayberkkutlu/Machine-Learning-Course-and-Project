{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f329a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS & CONFIGURATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdbab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\ayber\\OneDrive\\Masa端st端\\ML\\Data/processed/irb2400_ready_v2.csv\n",
      "Data shape: (300000, 27)\n",
      "   target_x  target_y  target_z   sin_yaw  cos_yaw  sin_pitch  cos_pitch  \\\n",
      "0 -0.080915  -0.12175  1.896487 -0.639694  0.76863   0.797355    0.60351   \n",
      "1 -0.080915  -0.12175  1.896487 -0.639694  0.76863   0.797355    0.60351   \n",
      "2 -0.080915  -0.12175  1.896487 -0.639694  0.76863   0.797355    0.60351   \n",
      "3 -0.080915  -0.12175  1.896487 -0.639694  0.76863   0.797355    0.60351   \n",
      "4 -0.080915  -0.12175  1.896487 -0.639694  0.76863   0.797355    0.60351   \n",
      "\n",
      "   sin_roll  cos_roll       q1_in  ...  delta_q3  delta_q4  delta_q5  \\\n",
      "0 -0.991601  0.129333 -128.382653  ... -2.509555  0.847978  5.185268   \n",
      "1 -0.991601  0.129333 -127.385707  ...  0.842248 -2.985110  2.606958   \n",
      "2 -0.991601  0.129333 -129.299386  ...  1.678766  1.856383  5.139431   \n",
      "3 -0.991601  0.129333 -123.512512  ...  3.328885 -4.858682 -3.323155   \n",
      "4 -0.991601  0.129333 -133.310090  ... -3.489313  0.148969 -0.853707   \n",
      "\n",
      "   delta_q6      q1_out     q2_out    q3_out      q4_out     q5_out  \\\n",
      "0 -1.489690 -128.038878 -51.273993  35.02491 -188.165069  69.425296   \n",
      "1  2.079837 -128.038878 -51.273993  35.02491 -188.165069  69.425296   \n",
      "2  4.858682 -128.038878 -51.273993  35.02491 -188.165069  69.425296   \n",
      "3 -3.907572 -128.038878 -51.273993  35.02491 -188.165069  69.425296   \n",
      "4  2.796034 -128.038878 -51.273993  35.02491 -188.165069  69.425296   \n",
      "\n",
      "       q6_out  \n",
      "0  325.394191  \n",
      "1  325.394191  \n",
      "2  325.394191  \n",
      "3  325.394191  \n",
      "4  325.394191  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# UPDATE: Using the v2 dataset\n",
    "BASE_DIR = r\"C:\\Users\\ayber\\OneDrive\\Masa端st端\\ML\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"Data/processed/irb2400_ready_v2.csv\") \n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"Models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b680a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features: 15 (Added Sin/Cos)\n"
     ]
    }
   ],
   "source": [
    "# 2. DEFINE NEW FEATURES\n",
    "# We replaced raw angles with Sin/Cos pairs\n",
    "feature_cols = [\n",
    "    'target_x', 'target_y', 'target_z', \n",
    "    'sin_yaw', 'cos_yaw', \n",
    "    'sin_pitch', 'cos_pitch', \n",
    "    'sin_roll', 'cos_roll',\n",
    "    'q1_in', 'q2_in', 'q3_in', 'q4_in', 'q5_in', 'q6_in'\n",
    "]\n",
    "\n",
    "target_cols = ['delta_q1', 'delta_q2', 'delta_q3', 'delta_q4', 'delta_q5', 'delta_q6']\n",
    "\n",
    "print(f\"Input Features: {len(feature_cols)} (Added Sin/Cos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257b5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PREPROCESSING\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "584506dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Wider MLP Regressor...\n",
      "Starting training...\n",
      "Iteration 1, loss = 0.49595660\n",
      "Validation score: 0.046503\n",
      "Iteration 2, loss = 0.43323422\n",
      "Validation score: 0.189327\n",
      "Iteration 3, loss = 0.39269988\n",
      "Validation score: 0.237761\n",
      "Iteration 4, loss = 0.36816476\n",
      "Validation score: 0.281435\n",
      "Iteration 5, loss = 0.34844948\n",
      "Validation score: 0.318316\n",
      "Iteration 6, loss = 0.33223293\n",
      "Validation score: 0.340754\n",
      "Iteration 7, loss = 0.31998629\n",
      "Validation score: 0.367788\n",
      "Iteration 8, loss = 0.31080125\n",
      "Validation score: 0.384048\n",
      "Iteration 9, loss = 0.30477595\n",
      "Validation score: 0.395539\n",
      "Iteration 10, loss = 0.29853829\n",
      "Validation score: 0.402057\n",
      "Iteration 11, loss = 0.29545542\n",
      "Validation score: 0.411325\n",
      "Iteration 12, loss = 0.29212671\n",
      "Validation score: 0.419316\n",
      "Iteration 13, loss = 0.28891079\n",
      "Validation score: 0.420790\n",
      "Iteration 14, loss = 0.28686637\n",
      "Validation score: 0.428777\n",
      "Iteration 15, loss = 0.28449828\n",
      "Validation score: 0.429570\n",
      "Iteration 16, loss = 0.28309209\n",
      "Validation score: 0.431132\n",
      "Iteration 17, loss = 0.28100064\n",
      "Validation score: 0.434123\n",
      "Iteration 18, loss = 0.28079760\n",
      "Validation score: 0.434964\n",
      "Iteration 19, loss = 0.27923783\n",
      "Validation score: 0.436953\n",
      "Iteration 20, loss = 0.27740837\n",
      "Validation score: 0.433906\n",
      "Iteration 21, loss = 0.27795015\n",
      "Validation score: 0.443484\n",
      "Iteration 22, loss = 0.27611511\n",
      "Validation score: 0.447578\n",
      "Iteration 23, loss = 0.27574444\n",
      "Validation score: 0.447084\n",
      "Iteration 24, loss = 0.27517677\n",
      "Validation score: 0.447351\n",
      "Iteration 25, loss = 0.27352590\n",
      "Validation score: 0.452378\n",
      "Iteration 26, loss = 0.27314531\n",
      "Validation score: 0.448492\n",
      "Iteration 27, loss = 0.27333601\n",
      "Validation score: 0.438081\n",
      "Iteration 28, loss = 0.27314650\n",
      "Validation score: 0.449879\n",
      "Iteration 29, loss = 0.27141745\n",
      "Validation score: 0.447747\n",
      "Iteration 30, loss = 0.27194265\n",
      "Validation score: 0.454125\n",
      "Iteration 31, loss = 0.27056575\n",
      "Validation score: 0.455382\n",
      "Iteration 32, loss = 0.26979315\n",
      "Validation score: 0.458987\n",
      "Iteration 33, loss = 0.27108817\n",
      "Validation score: 0.459869\n",
      "Iteration 34, loss = 0.26943321\n",
      "Validation score: 0.459414\n",
      "Iteration 35, loss = 0.26906160\n",
      "Validation score: 0.458618\n",
      "Iteration 36, loss = 0.26877600\n",
      "Validation score: 0.450971\n",
      "Iteration 37, loss = 0.26889884\n",
      "Validation score: 0.457962\n",
      "Iteration 38, loss = 0.26817807\n",
      "Validation score: 0.462073\n",
      "Iteration 39, loss = 0.26792672\n",
      "Validation score: 0.459942\n",
      "Iteration 40, loss = 0.26745313\n",
      "Validation score: 0.462189\n",
      "Iteration 41, loss = 0.26697741\n",
      "Validation score: 0.447026\n",
      "Iteration 42, loss = 0.26724226\n",
      "Validation score: 0.460360\n",
      "Iteration 43, loss = 0.26717307\n",
      "Validation score: 0.464577\n",
      "Iteration 44, loss = 0.26635264\n",
      "Validation score: 0.454911\n",
      "Iteration 45, loss = 0.26636832\n",
      "Validation score: 0.465395\n",
      "Iteration 46, loss = 0.26515357\n",
      "Validation score: 0.464058\n",
      "Iteration 47, loss = 0.26536599\n",
      "Validation score: 0.460991\n",
      "Iteration 48, loss = 0.26578114\n",
      "Validation score: 0.463921\n",
      "Iteration 49, loss = 0.26485216\n",
      "Validation score: 0.457386\n",
      "Iteration 50, loss = 0.26523570\n",
      "Validation score: 0.467039\n",
      "Iteration 51, loss = 0.26485669\n",
      "Validation score: 0.467222\n",
      "Iteration 52, loss = 0.26430751\n",
      "Validation score: 0.467179\n",
      "Iteration 53, loss = 0.26476910\n",
      "Validation score: 0.466011\n",
      "Iteration 54, loss = 0.26356400\n",
      "Validation score: 0.471053\n",
      "Iteration 55, loss = 0.26324550\n",
      "Validation score: 0.467239\n",
      "Iteration 56, loss = 0.26350951\n",
      "Validation score: 0.470162\n",
      "Iteration 57, loss = 0.26321535\n",
      "Validation score: 0.470485\n",
      "Iteration 58, loss = 0.26338983\n",
      "Validation score: 0.463763\n",
      "Iteration 59, loss = 0.26345647\n",
      "Validation score: 0.470774\n",
      "Iteration 60, loss = 0.26267022\n",
      "Validation score: 0.467252\n",
      "Iteration 61, loss = 0.26253138\n",
      "Validation score: 0.457737\n",
      "Iteration 62, loss = 0.26309521\n",
      "Validation score: 0.470104\n",
      "Iteration 63, loss = 0.26115386\n",
      "Validation score: 0.471482\n",
      "Iteration 64, loss = 0.26096681\n",
      "Validation score: 0.472896\n",
      "Iteration 65, loss = 0.26128381\n",
      "Validation score: 0.469856\n",
      "Iteration 66, loss = 0.26159254\n",
      "Validation score: 0.471190\n",
      "Iteration 67, loss = 0.26129310\n",
      "Validation score: 0.472241\n",
      "Iteration 68, loss = 0.26107998\n",
      "Validation score: 0.474436\n",
      "Iteration 69, loss = 0.26128193\n",
      "Validation score: 0.472315\n",
      "Iteration 70, loss = 0.26090259\n",
      "Validation score: 0.465816\n",
      "Iteration 71, loss = 0.26062151\n",
      "Validation score: 0.471380\n",
      "Iteration 72, loss = 0.26031522\n",
      "Validation score: 0.472932\n",
      "Iteration 73, loss = 0.25918558\n",
      "Validation score: 0.472345\n",
      "Iteration 74, loss = 0.25984151\n",
      "Validation score: 0.475171\n",
      "Iteration 75, loss = 0.25901600\n",
      "Validation score: 0.471487\n",
      "Iteration 76, loss = 0.25895683\n",
      "Validation score: 0.473992\n",
      "Iteration 77, loss = 0.25902670\n",
      "Validation score: 0.455541\n",
      "Iteration 78, loss = 0.25915909\n",
      "Validation score: 0.476260\n",
      "Iteration 79, loss = 0.25955010\n",
      "Validation score: 0.473293\n",
      "Iteration 80, loss = 0.25782321\n",
      "Validation score: 0.470548\n",
      "Iteration 81, loss = 0.25824185\n",
      "Validation score: 0.467621\n",
      "Iteration 82, loss = 0.25791080\n",
      "Validation score: 0.472430\n",
      "Iteration 83, loss = 0.25764736\n",
      "Validation score: 0.477754\n",
      "Iteration 84, loss = 0.25776377\n",
      "Validation score: 0.479274\n",
      "Iteration 85, loss = 0.25746394\n",
      "Validation score: 0.479968\n",
      "Iteration 86, loss = 0.25618896\n",
      "Validation score: 0.481027\n",
      "Iteration 87, loss = 0.25696204\n",
      "Validation score: 0.478414\n",
      "Iteration 88, loss = 0.25682238\n",
      "Validation score: 0.477137\n",
      "Iteration 89, loss = 0.25657009\n",
      "Validation score: 0.475579\n",
      "Iteration 90, loss = 0.25644642\n",
      "Validation score: 0.476488\n",
      "Iteration 91, loss = 0.25584355\n",
      "Validation score: 0.481188\n",
      "Iteration 92, loss = 0.25598831\n",
      "Validation score: 0.478881\n",
      "Iteration 93, loss = 0.25587104\n",
      "Validation score: 0.471281\n",
      "Iteration 94, loss = 0.25500395\n",
      "Validation score: 0.481348\n",
      "Iteration 95, loss = 0.25587648\n",
      "Validation score: 0.473444\n",
      "Iteration 96, loss = 0.25477434\n",
      "Validation score: 0.481283\n",
      "Iteration 97, loss = 0.25461435\n",
      "Validation score: 0.481982\n",
      "Iteration 98, loss = 0.25457081\n",
      "Validation score: 0.480000\n",
      "Iteration 99, loss = 0.25428152\n",
      "Validation score: 0.478720\n",
      "Iteration 100, loss = 0.25339898\n",
      "Validation score: 0.477747\n",
      "Iteration 101, loss = 0.25358144\n",
      "Validation score: 0.481972\n",
      "Iteration 102, loss = 0.25366026\n",
      "Validation score: 0.483251\n",
      "Iteration 103, loss = 0.25299328\n",
      "Validation score: 0.483157\n",
      "Iteration 104, loss = 0.25293348\n",
      "Validation score: 0.484139\n",
      "Iteration 105, loss = 0.25406096\n",
      "Validation score: 0.483533\n",
      "Iteration 106, loss = 0.25269124\n",
      "Validation score: 0.482612\n",
      "Iteration 107, loss = 0.25255626\n",
      "Validation score: 0.487410\n",
      "Iteration 108, loss = 0.25203805\n",
      "Validation score: 0.464049\n",
      "Iteration 109, loss = 0.25245616\n",
      "Validation score: 0.476320\n",
      "Iteration 110, loss = 0.25160813\n",
      "Validation score: 0.488708\n",
      "Iteration 111, loss = 0.25180133\n",
      "Validation score: 0.484380\n",
      "Iteration 112, loss = 0.25121504\n",
      "Validation score: 0.487411\n",
      "Iteration 113, loss = 0.25106004\n",
      "Validation score: 0.488630\n",
      "Iteration 114, loss = 0.25093069\n",
      "Validation score: 0.482229\n",
      "Iteration 115, loss = 0.25121290\n",
      "Validation score: 0.462422\n",
      "Iteration 116, loss = 0.25081752\n",
      "Validation score: 0.486354\n",
      "Iteration 117, loss = 0.25002036\n",
      "Validation score: 0.488002\n",
      "Iteration 118, loss = 0.25051389\n",
      "Validation score: 0.476168\n",
      "Iteration 119, loss = 0.25005981\n",
      "Validation score: 0.488376\n",
      "Iteration 120, loss = 0.25018895\n",
      "Validation score: 0.488846\n",
      "Iteration 121, loss = 0.24906276\n",
      "Validation score: 0.490064\n",
      "Iteration 122, loss = 0.24902263\n",
      "Validation score: 0.489647\n",
      "Iteration 123, loss = 0.24899534\n",
      "Validation score: 0.490348\n",
      "Iteration 124, loss = 0.24901707\n",
      "Validation score: 0.490423\n",
      "Iteration 125, loss = 0.24861007\n",
      "Validation score: 0.487130\n",
      "Iteration 126, loss = 0.24908012\n",
      "Validation score: 0.488315\n",
      "Iteration 127, loss = 0.24836127\n",
      "Validation score: 0.491684\n",
      "Iteration 128, loss = 0.24773589\n",
      "Validation score: 0.493565\n",
      "Iteration 129, loss = 0.24784095\n",
      "Validation score: 0.490866\n",
      "Iteration 130, loss = 0.24693276\n",
      "Validation score: 0.492709\n",
      "Iteration 131, loss = 0.24739161\n",
      "Validation score: 0.491030\n",
      "Iteration 132, loss = 0.24734738\n",
      "Validation score: 0.495035\n",
      "Iteration 133, loss = 0.24677224\n",
      "Validation score: 0.493075\n",
      "Iteration 134, loss = 0.24657158\n",
      "Validation score: 0.493946\n",
      "Iteration 135, loss = 0.24618264\n",
      "Validation score: 0.494023\n",
      "Iteration 136, loss = 0.24575228\n",
      "Validation score: 0.493974\n",
      "Iteration 137, loss = 0.24578272\n",
      "Validation score: 0.496692\n",
      "Iteration 138, loss = 0.24536261\n",
      "Validation score: 0.490474\n",
      "Iteration 139, loss = 0.24675143\n",
      "Validation score: 0.490805\n",
      "Iteration 140, loss = 0.24510625\n",
      "Validation score: 0.494955\n",
      "Iteration 141, loss = 0.24509404\n",
      "Validation score: 0.496682\n",
      "Iteration 142, loss = 0.24456389\n",
      "Validation score: 0.496924\n",
      "Iteration 143, loss = 0.24406422\n",
      "Validation score: 0.497421\n",
      "Iteration 144, loss = 0.24478680\n",
      "Validation score: 0.493797\n",
      "Iteration 145, loss = 0.24484222\n",
      "Validation score: 0.499030\n",
      "Iteration 146, loss = 0.24354905\n",
      "Validation score: 0.494861\n",
      "Iteration 147, loss = 0.24407365\n",
      "Validation score: 0.499224\n",
      "Iteration 148, loss = 0.24353883\n",
      "Validation score: 0.498107\n",
      "Iteration 149, loss = 0.24335219\n",
      "Validation score: 0.499534\n",
      "Iteration 150, loss = 0.24305150\n",
      "Validation score: 0.499565\n",
      "Iteration 151, loss = 0.24232007\n",
      "Validation score: 0.499209\n",
      "Iteration 152, loss = 0.24294621\n",
      "Validation score: 0.495084\n",
      "Iteration 153, loss = 0.24186762\n",
      "Validation score: 0.495148\n",
      "Iteration 154, loss = 0.24178180\n",
      "Validation score: 0.501873\n",
      "Iteration 155, loss = 0.24272870\n",
      "Validation score: 0.493924\n",
      "Iteration 156, loss = 0.24166325\n",
      "Validation score: 0.498765\n",
      "Iteration 157, loss = 0.24234867\n",
      "Validation score: 0.497141\n",
      "Iteration 158, loss = 0.24111575\n",
      "Validation score: 0.500326\n",
      "Iteration 159, loss = 0.24131877\n",
      "Validation score: 0.489817\n",
      "Iteration 160, loss = 0.24084625\n",
      "Validation score: 0.501836\n",
      "Iteration 161, loss = 0.24016910\n",
      "Validation score: 0.503098\n",
      "Iteration 162, loss = 0.24041361\n",
      "Validation score: 0.502423\n",
      "Iteration 163, loss = 0.24046654\n",
      "Validation score: 0.500883\n",
      "Iteration 164, loss = 0.23967867\n",
      "Validation score: 0.502949\n",
      "Iteration 165, loss = 0.23980206\n",
      "Validation score: 0.505121\n",
      "Iteration 166, loss = 0.23924257\n",
      "Validation score: 0.505539\n",
      "Iteration 167, loss = 0.23938327\n",
      "Validation score: 0.506193\n",
      "Iteration 168, loss = 0.23909752\n",
      "Validation score: 0.500752\n",
      "Iteration 169, loss = 0.23848439\n",
      "Validation score: 0.505889\n",
      "Iteration 170, loss = 0.23845238\n",
      "Validation score: 0.504812\n",
      "Iteration 171, loss = 0.23816249\n",
      "Validation score: 0.502299\n",
      "Iteration 172, loss = 0.23787574\n",
      "Validation score: 0.508634\n",
      "Iteration 173, loss = 0.23827278\n",
      "Validation score: 0.510816\n",
      "Iteration 174, loss = 0.23723257\n",
      "Validation score: 0.508897\n",
      "Iteration 175, loss = 0.23699471\n",
      "Validation score: 0.509280\n",
      "Iteration 176, loss = 0.23705318\n",
      "Validation score: 0.506375\n",
      "Iteration 177, loss = 0.23738657\n",
      "Validation score: 0.511097\n",
      "Iteration 178, loss = 0.23595385\n",
      "Validation score: 0.511676\n",
      "Iteration 179, loss = 0.23641301\n",
      "Validation score: 0.514070\n",
      "Iteration 180, loss = 0.23666879\n",
      "Validation score: 0.509246\n",
      "Iteration 181, loss = 0.23575037\n",
      "Validation score: 0.508519\n",
      "Iteration 182, loss = 0.23583636\n",
      "Validation score: 0.514415\n",
      "Iteration 183, loss = 0.23549019\n",
      "Validation score: 0.511817\n",
      "Iteration 184, loss = 0.23574590\n",
      "Validation score: 0.513111\n",
      "Iteration 185, loss = 0.23394017\n",
      "Validation score: 0.514914\n",
      "Iteration 186, loss = 0.23453503\n",
      "Validation score: 0.505897\n",
      "Iteration 187, loss = 0.23414545\n",
      "Validation score: 0.516715\n",
      "Iteration 188, loss = 0.23373231\n",
      "Validation score: 0.514873\n",
      "Iteration 189, loss = 0.23339861\n",
      "Validation score: 0.514444\n",
      "Iteration 190, loss = 0.23416911\n",
      "Validation score: 0.512984\n",
      "Iteration 191, loss = 0.23319665\n",
      "Validation score: 0.515936\n",
      "Iteration 192, loss = 0.23267183\n",
      "Validation score: 0.514144\n",
      "Iteration 193, loss = 0.23259846\n",
      "Validation score: 0.515379\n",
      "Iteration 194, loss = 0.23255077\n",
      "Validation score: 0.517912\n",
      "Iteration 195, loss = 0.23209669\n",
      "Validation score: 0.509839\n",
      "Iteration 196, loss = 0.23255207\n",
      "Validation score: 0.509543\n",
      "Iteration 197, loss = 0.23206265\n",
      "Validation score: 0.517081\n",
      "Iteration 198, loss = 0.23169921\n",
      "Validation score: 0.517032\n",
      "Iteration 199, loss = 0.23183498\n",
      "Validation score: 0.516793\n",
      "Iteration 200, loss = 0.23090908\n",
      "Validation score: 0.520935\n",
      "Iteration 201, loss = 0.23096477\n",
      "Validation score: 0.513774\n",
      "Iteration 202, loss = 0.23135524\n",
      "Validation score: 0.517158\n",
      "Iteration 203, loss = 0.23057996\n",
      "Validation score: 0.515193\n",
      "Iteration 204, loss = 0.23053560\n",
      "Validation score: 0.515577\n",
      "Iteration 205, loss = 0.23019525\n",
      "Validation score: 0.522423\n",
      "Iteration 206, loss = 0.23023960\n",
      "Validation score: 0.520677\n",
      "Iteration 207, loss = 0.22929230\n",
      "Validation score: 0.524046\n",
      "Iteration 208, loss = 0.22990200\n",
      "Validation score: 0.521225\n",
      "Iteration 209, loss = 0.22929754\n",
      "Validation score: 0.522327\n",
      "Iteration 210, loss = 0.22898764\n",
      "Validation score: 0.519932\n",
      "Iteration 211, loss = 0.22878879\n",
      "Validation score: 0.525945\n",
      "Iteration 212, loss = 0.22819168\n",
      "Validation score: 0.521016\n",
      "Iteration 213, loss = 0.22850372\n",
      "Validation score: 0.520840\n",
      "Iteration 214, loss = 0.22746393\n",
      "Validation score: 0.527856\n",
      "Iteration 215, loss = 0.22808376\n",
      "Validation score: 0.525628\n",
      "Iteration 216, loss = 0.22792549\n",
      "Validation score: 0.527329\n",
      "Iteration 217, loss = 0.22742212\n",
      "Validation score: 0.522750\n",
      "Iteration 218, loss = 0.22710916\n",
      "Validation score: 0.525767\n",
      "Iteration 219, loss = 0.22774419\n",
      "Validation score: 0.521160\n",
      "Iteration 220, loss = 0.22710962\n",
      "Validation score: 0.522599\n",
      "Iteration 221, loss = 0.22658191\n",
      "Validation score: 0.527284\n",
      "Iteration 222, loss = 0.22595364\n",
      "Validation score: 0.525156\n",
      "Iteration 223, loss = 0.22688913\n",
      "Validation score: 0.527590\n",
      "Iteration 224, loss = 0.22651892\n",
      "Validation score: 0.523734\n",
      "Iteration 225, loss = 0.22609510\n",
      "Validation score: 0.524735\n",
      "Iteration 226, loss = 0.22569276\n",
      "Validation score: 0.527701\n",
      "Iteration 227, loss = 0.22534598\n",
      "Validation score: 0.530270\n",
      "Iteration 228, loss = 0.22484743\n",
      "Validation score: 0.532701\n",
      "Iteration 229, loss = 0.22511799\n",
      "Validation score: 0.528619\n",
      "Iteration 230, loss = 0.22573355\n",
      "Validation score: 0.532594\n",
      "Iteration 231, loss = 0.22444047\n",
      "Validation score: 0.534128\n",
      "Iteration 232, loss = 0.22406054\n",
      "Validation score: 0.532013\n",
      "Iteration 233, loss = 0.22432044\n",
      "Validation score: 0.526404\n",
      "Iteration 234, loss = 0.22356546\n",
      "Validation score: 0.534109\n",
      "Iteration 235, loss = 0.22402973\n",
      "Validation score: 0.530390\n",
      "Iteration 236, loss = 0.22363101\n",
      "Validation score: 0.534749\n",
      "Iteration 237, loss = 0.22341727\n",
      "Validation score: 0.528441\n",
      "Iteration 238, loss = 0.22353378\n",
      "Validation score: 0.532256\n",
      "Iteration 239, loss = 0.22288547\n",
      "Validation score: 0.531946\n",
      "Iteration 240, loss = 0.22293457\n",
      "Validation score: 0.531896\n",
      "Iteration 241, loss = 0.22266196\n",
      "Validation score: 0.533279\n",
      "Iteration 242, loss = 0.22258681\n",
      "Validation score: 0.537350\n",
      "Iteration 243, loss = 0.22230618\n",
      "Validation score: 0.538447\n",
      "Iteration 244, loss = 0.22226042\n",
      "Validation score: 0.537297\n",
      "Iteration 245, loss = 0.22235121\n",
      "Validation score: 0.537699\n",
      "Iteration 246, loss = 0.22208011\n",
      "Validation score: 0.537265\n",
      "Iteration 247, loss = 0.22214308\n",
      "Validation score: 0.532931\n",
      "Iteration 248, loss = 0.22117996\n",
      "Validation score: 0.539040\n",
      "Iteration 249, loss = 0.22160812\n",
      "Validation score: 0.539696\n",
      "Iteration 250, loss = 0.22138141\n",
      "Validation score: 0.529432\n",
      "Iteration 251, loss = 0.22105224\n",
      "Validation score: 0.538508\n",
      "Iteration 252, loss = 0.22068538\n",
      "Validation score: 0.535927\n",
      "Iteration 253, loss = 0.22065401\n",
      "Validation score: 0.537647\n",
      "Iteration 254, loss = 0.22001646\n",
      "Validation score: 0.539616\n",
      "Iteration 255, loss = 0.21992441\n",
      "Validation score: 0.538349\n",
      "Iteration 256, loss = 0.22033945\n",
      "Validation score: 0.536146\n",
      "Iteration 257, loss = 0.22085198\n",
      "Validation score: 0.540341\n",
      "Iteration 258, loss = 0.21994969\n",
      "Validation score: 0.540726\n",
      "Iteration 259, loss = 0.21930958\n",
      "Validation score: 0.530560\n",
      "Iteration 260, loss = 0.21939551\n",
      "Validation score: 0.543832\n",
      "Iteration 261, loss = 0.21864046\n",
      "Validation score: 0.538694\n",
      "Iteration 262, loss = 0.21951043\n",
      "Validation score: 0.539291\n",
      "Iteration 263, loss = 0.21889875\n",
      "Validation score: 0.542658\n",
      "Iteration 264, loss = 0.21906582\n",
      "Validation score: 0.543101\n",
      "Iteration 265, loss = 0.21914451\n",
      "Validation score: 0.543970\n",
      "Iteration 266, loss = 0.21827632\n",
      "Validation score: 0.539735\n",
      "Iteration 267, loss = 0.21850782\n",
      "Validation score: 0.537956\n",
      "Iteration 268, loss = 0.21842673\n",
      "Validation score: 0.534735\n",
      "Iteration 269, loss = 0.21881012\n",
      "Validation score: 0.543192\n",
      "Iteration 270, loss = 0.21754075\n",
      "Validation score: 0.541912\n",
      "Iteration 271, loss = 0.21755099\n",
      "Validation score: 0.539395\n",
      "Iteration 272, loss = 0.21765880\n",
      "Validation score: 0.543517\n",
      "Iteration 273, loss = 0.21749407\n",
      "Validation score: 0.543240\n",
      "Iteration 274, loss = 0.21710724\n",
      "Validation score: 0.540420\n",
      "Iteration 275, loss = 0.21779899\n",
      "Validation score: 0.544451\n",
      "Iteration 276, loss = 0.21699835\n",
      "Validation score: 0.543901\n",
      "Iteration 277, loss = 0.21713241\n",
      "Validation score: 0.545704\n",
      "Iteration 278, loss = 0.21659587\n",
      "Validation score: 0.543721\n",
      "Iteration 279, loss = 0.21691599\n",
      "Validation score: 0.549042\n",
      "Iteration 280, loss = 0.21645706\n",
      "Validation score: 0.537531\n",
      "Iteration 281, loss = 0.21673556\n",
      "Validation score: 0.536405\n",
      "Iteration 282, loss = 0.21580928\n",
      "Validation score: 0.543163\n",
      "Iteration 283, loss = 0.21600996\n",
      "Validation score: 0.539360\n",
      "Iteration 284, loss = 0.21546564\n",
      "Validation score: 0.540061\n",
      "Iteration 285, loss = 0.21531805\n",
      "Validation score: 0.548760\n",
      "Iteration 286, loss = 0.21594753\n",
      "Validation score: 0.545014\n",
      "Iteration 287, loss = 0.21537079\n",
      "Validation score: 0.549687\n",
      "Iteration 288, loss = 0.21594388\n",
      "Validation score: 0.546148\n",
      "Iteration 289, loss = 0.21553625\n",
      "Validation score: 0.548406\n",
      "Iteration 290, loss = 0.21523192\n",
      "Validation score: 0.540225\n",
      "Iteration 291, loss = 0.21510069\n",
      "Validation score: 0.547515\n",
      "Iteration 292, loss = 0.21470559\n",
      "Validation score: 0.547226\n",
      "Iteration 293, loss = 0.21522044\n",
      "Validation score: 0.550944\n",
      "Iteration 294, loss = 0.21396240\n",
      "Validation score: 0.551878\n",
      "Iteration 295, loss = 0.21380123\n",
      "Validation score: 0.549005\n",
      "Iteration 296, loss = 0.21392306\n",
      "Validation score: 0.551757\n",
      "Iteration 297, loss = 0.21459962\n",
      "Validation score: 0.551744\n",
      "Iteration 298, loss = 0.21383128\n",
      "Validation score: 0.548483\n",
      "Iteration 299, loss = 0.21348936\n",
      "Validation score: 0.553271\n",
      "Iteration 300, loss = 0.21383790\n",
      "Validation score: 0.553998\n",
      "Iteration 301, loss = 0.21384987\n",
      "Validation score: 0.553334\n",
      "Iteration 302, loss = 0.21333013\n",
      "Validation score: 0.548689\n",
      "Iteration 303, loss = 0.21271316\n",
      "Validation score: 0.549021\n",
      "Iteration 304, loss = 0.21339366\n",
      "Validation score: 0.551797\n",
      "Iteration 305, loss = 0.21318515\n",
      "Validation score: 0.545802\n",
      "Iteration 306, loss = 0.21329986\n",
      "Validation score: 0.553749\n",
      "Iteration 307, loss = 0.21299995\n",
      "Validation score: 0.551204\n",
      "Iteration 308, loss = 0.21260023\n",
      "Validation score: 0.552483\n",
      "Iteration 309, loss = 0.21323888\n",
      "Validation score: 0.550661\n",
      "Iteration 310, loss = 0.21175471\n",
      "Validation score: 0.551906\n",
      "Iteration 311, loss = 0.21199901\n",
      "Validation score: 0.550838\n",
      "Iteration 312, loss = 0.21235743\n",
      "Validation score: 0.556669\n",
      "Iteration 313, loss = 0.21266561\n",
      "Validation score: 0.550523\n",
      "Iteration 314, loss = 0.21181200\n",
      "Validation score: 0.554128\n",
      "Iteration 315, loss = 0.21131601\n",
      "Validation score: 0.555520\n",
      "Iteration 316, loss = 0.21146234\n",
      "Validation score: 0.541094\n",
      "Iteration 317, loss = 0.21176894\n",
      "Validation score: 0.551658\n",
      "Iteration 318, loss = 0.21061295\n",
      "Validation score: 0.559710\n",
      "Iteration 319, loss = 0.21150100\n",
      "Validation score: 0.553321\n",
      "Iteration 320, loss = 0.21110467\n",
      "Validation score: 0.555780\n",
      "Iteration 321, loss = 0.21096398\n",
      "Validation score: 0.545498\n",
      "Iteration 322, loss = 0.21120715\n",
      "Validation score: 0.559291\n",
      "Iteration 323, loss = 0.21123111\n",
      "Validation score: 0.559853\n",
      "Iteration 324, loss = 0.20958818\n",
      "Validation score: 0.556005\n",
      "Iteration 325, loss = 0.21058972\n",
      "Validation score: 0.550418\n",
      "Iteration 326, loss = 0.21030538\n",
      "Validation score: 0.552667\n",
      "Iteration 327, loss = 0.21062479\n",
      "Validation score: 0.558486\n",
      "Iteration 328, loss = 0.21054201\n",
      "Validation score: 0.559353\n",
      "Iteration 329, loss = 0.21029203\n",
      "Validation score: 0.555228\n",
      "Iteration 330, loss = 0.21083632\n",
      "Validation score: 0.550915\n",
      "Iteration 331, loss = 0.20975126\n",
      "Validation score: 0.557497\n",
      "Iteration 332, loss = 0.20952934\n",
      "Validation score: 0.559099\n",
      "Iteration 333, loss = 0.20952522\n",
      "Validation score: 0.557181\n",
      "Iteration 334, loss = 0.20944001\n",
      "Validation score: 0.557123\n",
      "Iteration 335, loss = 0.20911774\n",
      "Validation score: 0.562031\n",
      "Iteration 336, loss = 0.21028957\n",
      "Validation score: 0.553062\n",
      "Iteration 337, loss = 0.20973292\n",
      "Validation score: 0.549086\n",
      "Iteration 338, loss = 0.20880433\n",
      "Validation score: 0.551548\n",
      "Iteration 339, loss = 0.20890172\n",
      "Validation score: 0.555660\n",
      "Iteration 340, loss = 0.20897016\n",
      "Validation score: 0.560961\n",
      "Iteration 341, loss = 0.20860993\n",
      "Validation score: 0.556274\n",
      "Iteration 342, loss = 0.20920678\n",
      "Validation score: 0.558837\n",
      "Iteration 343, loss = 0.20823655\n",
      "Validation score: 0.560359\n",
      "Iteration 344, loss = 0.20785950\n",
      "Validation score: 0.563781\n",
      "Iteration 345, loss = 0.20834586\n",
      "Validation score: 0.557008\n",
      "Iteration 346, loss = 0.20802803\n",
      "Validation score: 0.564315\n",
      "Iteration 347, loss = 0.20811973\n",
      "Validation score: 0.561538\n",
      "Iteration 348, loss = 0.20782479\n",
      "Validation score: 0.565776\n",
      "Iteration 349, loss = 0.20827968\n",
      "Validation score: 0.563026\n",
      "Iteration 350, loss = 0.20818131\n",
      "Validation score: 0.561858\n",
      "Iteration 351, loss = 0.20813391\n",
      "Validation score: 0.556653\n",
      "Iteration 352, loss = 0.20720481\n",
      "Validation score: 0.564181\n",
      "Iteration 353, loss = 0.20764858\n",
      "Validation score: 0.560264\n",
      "Iteration 354, loss = 0.20725855\n",
      "Validation score: 0.565695\n",
      "Iteration 355, loss = 0.20706292\n",
      "Validation score: 0.562782\n",
      "Iteration 356, loss = 0.20693097\n",
      "Validation score: 0.563383\n",
      "Iteration 357, loss = 0.20769201\n",
      "Validation score: 0.560801\n",
      "Iteration 358, loss = 0.20752801\n",
      "Validation score: 0.566551\n",
      "Iteration 359, loss = 0.20635081\n",
      "Validation score: 0.565629\n",
      "Iteration 360, loss = 0.20611376\n",
      "Validation score: 0.565931\n",
      "Iteration 361, loss = 0.20667444\n",
      "Validation score: 0.565853\n",
      "Iteration 362, loss = 0.20716281\n",
      "Validation score: 0.557498\n",
      "Iteration 363, loss = 0.20590050\n",
      "Validation score: 0.564534\n",
      "Iteration 364, loss = 0.20622496\n",
      "Validation score: 0.565388\n",
      "Iteration 365, loss = 0.20715696\n",
      "Validation score: 0.565340\n",
      "Iteration 366, loss = 0.20596094\n",
      "Validation score: 0.565199\n",
      "Iteration 367, loss = 0.20587113\n",
      "Validation score: 0.564319\n",
      "Iteration 368, loss = 0.20636696\n",
      "Validation score: 0.566454\n",
      "Iteration 369, loss = 0.20610697\n",
      "Validation score: 0.565035\n",
      "Validation score did not improve more than tol=0.001000 for 20 consecutive epochs. Stopping.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# WIDER MODEL TRAINING\n",
    "# NOTE on MAE: MLPRegressor does not support 'absolute_error' loss directly.\n",
    "# However, making the network wider (more neurons) helps it approximate the function better,\n",
    "# which reduces MAE indirectly.\n",
    "\n",
    "print(\"Initializing Wider MLP Regressor...\")\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(512, 256, 128),  # Significantly Wider & Deeper\n",
    "    activation='relu',                   # ReLU activation for non-linearity\n",
    "    solver='adam',                       # Adam optimizer\n",
    "    max_iter=500,                        # More iterations for convergence   \n",
    "    batch_size=1024,                     # Larger batch size for stability\n",
    "    learning_rate_init=0.001,            # Slightly higher LR for faster convergence\n",
    "    tol=0.001,                           # Loose tolerance for faster training\n",
    "    early_stopping=True,                 # Enable early stopping\n",
    "    validation_fraction=0.1,             # 10% for validation\n",
    "    n_iter_no_change=20,                 # Lower patience for early stopping\n",
    "    random_state=2,                      # For reproducibility\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815fe8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "       V2 MODEL RESULTS       \n",
      "==============================\n",
      "Mean Absolute Error: 1.4894 degrees\n",
      "RMSE:                2.1819 degrees\n",
      "------------------------------\n",
      "Saved v2 models.\n"
     ]
    }
   ],
   "source": [
    "# 5. EVALUATION\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"       V2 MODEL RESULTS       \")\n",
    "print(\"=\"*30)\n",
    "print(f\"Mean Absolute Error: {mae:.4f} degrees\")\n",
    "print(f\"RMSE:                {rmse:.4f} degrees\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 6. SAVE UPDATED MODELS\n",
    "joblib.dump(model, os.path.join(MODEL_DIR, \"mlp_baseline_v2.pkl\"))\n",
    "joblib.dump(scaler_x, os.path.join(MODEL_DIR, \"scaler_x_v2.pkl\"))\n",
    "joblib.dump(scaler_y, os.path.join(MODEL_DIR, \"scaler_y_v2.pkl\"))\n",
    "print(\"Saved v2 models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
